from prophet import Prophet
import pandas as pd
from google.cloud import storage, bigquery
import pickle

PROJECT_ID = "YOUR_PROJECT_ID"
BUCKET_NAME = "cpu-forecast-models"
BQ_TABLE = "YOUR_DATASET.cpu_history"

bq = bigquery.Client(project=PROJECT_ID)
query = f"SELECT time AS ds, value AS y FROM `{BQ_TABLE}` ORDER BY ds"
df = bq.query(query).to_dataframe()

df['ds'] = pd.to_datetime(df['ds'])
df['y'] = df['y'].astype(float)

model = Prophet(interval_width=0.95)
model.fit(df[['ds', 'y']])

pickle.dump(model, open("cpu_model.pkl", "wb"))

storage.Client().bucket(BUCKET_NAME).blob("models/cpu_model.pkl")\
    .upload_from_filename("cpu_model.pkl")

print("âœ… Model trained & uploaded successfully!")